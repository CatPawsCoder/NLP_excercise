{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e54c576-e059-4ce1-a0b8-93df5cd475b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f27c62c-19bc-4bf2-9454-4424fd5fca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for lecture1.txt:\n",
      "В начале 1990х годов объединение элементов ООП в Паскале с визуальной технологией программирования привело к созданию системы программирования Delphi.7.2 Структура процедурных языков программирования высокого уровняВо всяком языке программирования определены способы организации данных и способы организаций действий над данными. Следующие конструкции представляют собой комментарии и поэтому пропускаются компиляторомлюбой текст не содержащий символ фигурная скобка любой текст не содержащий символы звездочка круглая скобкапоследующий текст до конца строки.Буквы русского алфавита употребляются только в комментариях символьных и текстовых константах.Концепция типов данных является одной из центральных в любом языке программирования. Паскаль характеризуется большим разнообразием типов данных отраженным на рисунке 9.Рисунок 9  Система типов данных языка Паскаль79Тип данных называется порядковым если он состоит из счетного количества значений которые можно пронумеровать. К простым типам пользователя относятся перечислимый и интервальный типы данных.Перечислимый тип задается непосредственно перечислением списком всех значений которые может принимать переменная данного типаТуре имя типа  список значений80Определенное таким образом имя типа затем используется для описания переменных. Его элементы пронумерованы начиная от 0 в порядке следования в описании.В программе в которой присутствует данное выше описание переменной Day возможен такой фрагментОграниченный тип задается как упорядоченное ограниченное подмножество некоторого порядкового типаконстанта 1..константа 2Порядковый номер первой константы не должен превышать номера второй константы в соответствующем базовом типе.\n",
      "Topics for lecture1.txt: программирования, данных, типов, языка, типа, значений, типы, тип, программы, паскаля\n",
      "\n",
      "\n",
      "Summary for lecture2.txt:\n",
      "Файлы создаваемые с помощью текстовых процессоров например Microsoft Word включают в себя не только коды символов алфавита но и данные формата тип и размер шрифта положение строк поля отступы и прочую дополнительную информацию.1.3 Графическая информацияПринцип дискретности компьютерных данных справедлив и для графики. Однако в основе все равно лежит печать близких друг к другу точек.В зависимости от того на какое графическое разрешение экрана настроена операционная система компьютера на экране могут размещаться изображения имеющие размер 640x480 800x600 1024x768 и более пикселей. Стандартный фотоснимок размером 10x15 см2должен содержать примерно 1000x1500 пикселей.Дискретное представление цвета.Восстановим ваши знания о кодировании цвета полученные из базового курса информатики.\n",
      "Topics for lecture2.txt: носителе, кодировок, информацию, иным, использованием, используемых, итоге, каждой, какое, качество\n",
      "\n",
      "\n",
      "Summary for lecture3.txt:\n",
      "Согласно Колмогорову количество информации содержащееся в тексте определяется минимально возможной длиной двоичного кода необходимого для представления этого текста.Для определения информационного веса символа полезно знать ряд целых степеней двойки 2 4 8 16 32 64 128 256 и т.д.. Поскольку мощность N алфавита может не являться целой степенью двойки информационный вес символа алфавита мощности N определяется следующим образом. В стандартную кодовую таблицу например используемую в ОС Windows таблицу ANSI помещаются все необходимые символы английские и русские буквы  прописные и строчные цифры знаки препинания знаки арифметических операций всевозможные скобки и пр.Более крупной чем бит единицей измерения информации является байт 1 байт  8 битов.Информационный объем текста в памяти компьютера измеряется в байтах.\n",
      "Topics for lecture3.txt: языка, информация, использовать, используемую, используется, исходного, итак, ичный, кавычки, каждая\n",
      "\n",
      "\n",
      "Summary for lecture4.txt:\n",
      "После подведения итогов голосования вы узнали что избран Н. Н. Никитин.Вопрос в какой из трех ситуаций полученное сообщение несет больше информации Неопределенность знания  это количество возможных вариантов ответа на интересовавший вас вопрос. Здесь событие  выборы мэра исход  выбор например Н. Н. Никитина.В первой ситуации 2 варианта ответа мужчина женщина во второй ситуации 3 варианта выиграл Зенит ничья выиграло Динамо в третьей ситуации  4 варианта 4 кандидата на пост мэра.Согласно данному выше определению наибольшее количество информации несет сообщение в третьей ситуации поскольку неопределенность знания об исходе события в этом случае была наибольшей.В 40х годах XX века проблема измерения информации была решена американским ученым Клодом Шенноном  основателем теории информации. С ответом на каждый вопрос неопределенность знания уменьшалась в 2 раза и следовательно согласно данному выше определению передавался 1 бит информации.\n",
      "Topics for lecture4.txt: информации, знания, неопределенность, несет, вопрос, это, сообщение, количество, события, бит\n",
      "\n",
      "\n",
      "Summary for lecture5.txt:\n",
      "15 выборка разделится на 2 части в одной будут пациенты с температурой выше 37 C в другой  ниже 37 C. Далее часть выборки с пациентами имеющими температуру выше 37 C будет снова разделена на две части. Аналогично будет разделена и часть выборки с температурой тела ниже 37 C. В конечном итоге будут получены 7 групп по числу листов дерева из первоначальной выборки.Решающие деревья чаще всего применяются для задач классификации.\n",
      "Topics for lecture5.txt: ясен, ломота, ную, новый, новые, некоторые, начинается, нахождению, находится, наличия\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Глобальная переменная для хранения содержания лекции\n",
    "lecture_content = \"\"\n",
    "\n",
    "def read_lecture(file_path):\n",
    "    global lecture_content\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lecture_content = f.read()\n",
    "\n",
    "def process_lecture():\n",
    "    \n",
    "    global lecture_content\n",
    "    threshold=1.9\n",
    "    cosine_similarity_threshold=0.8\n",
    "    \n",
    "    # Очистка лекции от лишних символов\n",
    "    lecture_clean = re.sub(r'[^\\w\\s.\\\\n\\n]', '', lecture_content)\n",
    "    lecture_clean = lecture_clean.replace('\\n', '')\n",
    "\n",
    "    # Замена точек на пробелы для последующего токенизирования\n",
    "    lecture_clean_words = lecture_clean.replace('.', ' ')\n",
    "    \n",
    "    # Удаление стоп-слов и токенизация\n",
    "    stopWords = set(stopwords.words(\"russian\"))\n",
    "    words = word_tokenize(lecture_clean_words)\n",
    "\n",
    "    # Подсчет частоты слов\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    # Токенизация предложений и определение роли каждого предложения\n",
    "    sentences = sent_tokenize(lecture_clean)\n",
    "    sentenceRole = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for word, freq in freqTable.items():\n",
    "            if word in sentence.lower():\n",
    "                if sentence in sentenceRole:\n",
    "                    sentenceRole[sentence] += freq\n",
    "                else:\n",
    "                    sentenceRole[sentence] = freq\n",
    "    \n",
    "    sumRole = sum(sentenceRole.values())\n",
    "    averageRole = int(sumRole / len(sentenceRole))\n",
    "\n",
    "    # Использование TF-IDF для выделения ключевых предложений\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    summary_sentences = [sentences[i] for i in range(len(sentences))\n",
    "                         if (sentenceRole[sentences[i]] > (threshold*averageRole) and\n",
    "                             np.max(cosine_similarities[i, :]) > cosine_similarity_threshold)]\n",
    "\n",
    "    # Формирование итогового резюме\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def extract_topics(num_topics=5):\n",
    "    global lecture_content\n",
    "    \n",
    "    # Удаление стоп-слов и токенизация\n",
    "    stop_words = stopwords.words(\"russian\")\n",
    "    vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "    X = vectorizer.fit_transform([lecture_content])\n",
    "\n",
    "    # Применение LDA для извлечения тем\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=2)\n",
    "    lda.fit(X)\n",
    "\n",
    "    train_topics = lda.transform(X)\n",
    "\n",
    "    topic_word_matrix = lda.components_\n",
    "\n",
    "    # Извлечение топ-10 слов для каждой темы\n",
    "    topics_words = []\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for topic_weights in topic_word_matrix:\n",
    "        topic_words = [feature_names[i] for i in topic_weights.argsort()[:-10 - 1:-1]]\n",
    "        topics_words.append(topic_words)\n",
    "\n",
    "    return train_topics, topics_words\n",
    "\n",
    "# Список файлов для лекций\n",
    "lecture_files = [\"lecture1.txt\", \"lecture2.txt\", \"lecture3.txt\", \"lecture4.txt\", \"lecture5.txt\"]\n",
    "\n",
    "# Обработка каждой лекции отдельно\n",
    "for i, lecture_file in enumerate(lecture_files):\n",
    "    read_lecture(lecture_file)\n",
    "    \n",
    "    # Обработка лекции и вывод результатов\n",
    "    lecture_summary = process_lecture()\n",
    "    print(f\"Summary for {lecture_file}:\\n{lecture_summary}\")\n",
    "\n",
    "    lecture_topics, topics_words = extract_topics()\n",
    "    print(f\"Topics for {lecture_file}: {', '.join(topics_words[0])}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b9dca-2335-4fb7-a535-6837a3c955c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
